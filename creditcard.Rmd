---
title: "Credit Card Customers"
subtitle: "Data Annalisys and Prediction Models"
output:
  html_document:
    theme: paper
    toc: true
    toc_depth: 3
    df_print: paged
    code_folding: hide
author: ""
date: "2023"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# About Dataset
A manager at the bank is disturbed with more and more customers leaving their credit card services. They would really appreciate if one could predict for them who is gonna get churned so they can proactively go to the customer to provide them better services and turn customers' decisions in the opposite direction.

# Organizing the data
First, we're are going to set up the data and open the necessary packages. Since the data set has no NA's, we won't need to input any values.
```{r,message=FALSE, out.width="100%", fig.align = "center", results='asis'}
##used packages
library(ggplot2) # Data visualization
library(ggpubr) # Data visualization
library(plotly) # Interactive data visualizations
library(rattle) # Graphing decision trees
library(caret) # Machine learning
library(knitr) # Print tables
library(RColorBrewer) # Color palette
library(stargazer) # Tables 
library(tidyverse) # Organizing data
library(GGally) # Correlation plots
library(caTools) # Organizing Data
library(glm2) # Log regression
``` 
We can reoder the Income Category and Educational Level Variables, in order to make the graphs a bit more organized.
```{r,message=FALSE, fig.align = "center", results='asis'}
df <- read.csv("C:/Users/guima/Documents/r/Credit Card customers/BankChurners.csv")

df <- df %>%
  select(!CLIENTNUM) 

df$Income_Category <- factor(df$Income_Category, levels = c("Unknown", "Less than $40K", "$40K - $60K", "$60K - $80K", "$80K - $120K", "$120K +"))

df$Education_Level <- factor(df$Education_Level, levels = c("Unknown", "Uneducated", "High School", "College", "Graduate", "Post-Graduate", "Doctorate"))
```
Other than that, we are going to drop the Naive Bayes variables.
```{r,message=FALSE, fig.align = "center", results='asis'}
df <- df %>%
  select(!Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1) %>%
  select(!Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2) %>%
  mutate(att = ifelse(Attrition_Flag == "Existing Customer", 0, 1))
``` 

# Overview
In this section we are going to get an overview of some of the main variables in the data set. The goal is to get some insights that might help us understand which factors play an important role in the decision to leave the bank.

## Customers Annalysis
### Age Distribution
We can see that the age distibuition follows basically a normal distribution.
```{r,message=FALSE, fig.align = "center", results='asis'}
df %>%
  ggplot(aes(x=Customer_Age)) +
  geom_histogram( binwidth=5, colour="white", fill="#E41A1C", alpha=0.8) +
  geom_density(eval(bquote(aes(y=after_stat(count)*5))),colour="#FF7F00", fill="#FF7F00", alpha=0.3) + 
  scale_x_continuous(breaks=seq(20,75,5)) +
  geom_vline(xintercept = 46, linetype="dashed") +
  annotate("text", x=35, y=2250, label="Age below median", size=4, color="black") + 
  annotate("text", x=65, y=2250, label="Age above median", size=4, color="black") +
  theme_light() +
  labs(title="Age Distribution",
       fill="",
       x="",
       y="") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
``` 
The table below consists in the information about the clients, based on their gender, education level and income category.
### Gender, education and income
```{r,message=FALSE, fig.align = "center", results='asis'}
df %>%
  mutate(Gendert = ifelse(Gender == "M", "Male", "Female")) %>%
  group_by(Gendert, Income_Category, Education_Level) %>%
  summarise(amount = n()) %>%
  mutate(percentage = amount*100/sum(amount))
``` 

## What characteristics really matter?

### Correlogram
The first thing we can is plot a simple correlogram. This will give us a quick visual representation of the interaction between the variables and hopefully will also help us understand which elements are more strongly correlated with the attrition variable.
```{r,message=FALSE, fig.align = "center", results='asis'}
df %>%
  ggcorr(method = c("everything", "pearson"), low = "#FFFF33", mid = "#FF7F00"  , high = "#E41A1C", 
         label = TRUE, label_size = 4, label_color = "white",size =4, layout.exp =1) +
  labs(title="Basic Correlogram",
       x="",
       y="") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold")) +
  theme(legend.position="bottom")
``` 
The correlogram indicates that the strongest correlations revolve around average utilization, transactions and balance. We are going to get a more visual representation below.
### Balance
As expected, regardless of the income level, the balance for attrited customers tends to be lower.
```{r,message=FALSE, fig.align = "center", results='asis'}
df %>%
  group_by(Income_Category, `Attrition_Flag`) %>%
  summarise(amount = mean(Total_Revolving_Bal)) %>%
  ggplot(aes(fill=`Attrition_Flag`, y=amount, x=`Attrition_Flag`)) + 
  geom_bar(position="dodge", stat="identity") +
  scale_fill_brewer(palette = "Set1") +
  scale_y_continuous(labels = scales::label_dollar(scale = 1)) +
  facet_wrap(~`Income_Category`) +
  theme_light() +
  labs(title="Average revolving balance by income category",
       fill="Attrition Flag",
       x="",
       y="") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold")) +
  theme(legend.position="top")
``` 

### Card Type
Although card type does not seem to hold a significant importance, it is interesting to note that Platinum card users have a slightly superior percentage of attrited users. 
```{r,message=FALSE, fig.align = "center", results='asis'}
df %>%
  group_by(Card_Category,`Attrition_Flag`) %>%
  summarise(amount = n()) %>%
  mutate(percentage = amount*100/sum(amount)) %>%
  ggplot(aes(fill=`Attrition_Flag`, y=percentage, x=`Attrition_Flag`)) + 
  geom_bar(position="dodge", stat="identity") +
  scale_fill_brewer(palette = "Set1") +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  facet_wrap(~`Card_Category`) +
  theme_light() +
  labs(title="(%) of attrition by Card type",
       fill="Attrition Flag",
       x="",
       y="") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold")) +
  theme(legend.position="top")
``` 

### Differences in trasanction
The transaction count shows a clear difference between the customers - existing customers have a much higher count in the last 12 months than attrited ones.
```{r,message=FALSE, fig.align = "center", results='asis'}
df %>%
  ggplot(aes(fill=Education_Level, y=Total_Trans_Ct, x=Attrition_Flag)) + 
  geom_boxplot() +
  theme(legend.position="none") +
  scale_fill_brewer(palette = "Set1") +
  theme_light() +
  facet_wrap(~`Income_Category`) +
  labs(title="Transaction Count by groups",
       fill="Education",
       x="",
       y="") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold")) +
  theme(legend.position="top")
```
The conclusion holds true when it comes to the average amounts of transactions, with existing custumers holding much higher levels than the others.
```{r,message=FALSE, fig.align = "center", results='asis'}
df %>%
  ggplot(aes(fill=Education_Level, y=Total_Trans_Amt, x=Attrition_Flag)) + 
  geom_boxplot() +
  theme(legend.position="none") +
  scale_fill_brewer(palette = "Set1") +
  theme_light() +
  facet_wrap(~`Income_Category`) +
  labs(title="Transaction amount by groups",
       fill="Education",
       x="",
       y="") +
  scale_y_continuous(labels = scales::label_dollar(scale = 1)) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold")) +
  theme(legend.position="top")
``` 
The table below presents this relationship, but now grouped by the Card type.
```{r,message=FALSE, fig.align = "center", results='asis'}
df %>%
  group_by(Card_Category,Attrition_Flag) %>%
  summarise(`Average Transactions Count` = mean(Total_Trans_Ct),
            `Average Transactions Amount` = mean(Total_Trans_Amt))
```

# Prediction Models
Having made these overall observations, we can now move on to the prediction models. We will use 4 different models and compare their results.

## Logistic regression

```{r,message=FALSE, fig.align = "center", results='asis'}
set.seed(237)

train_index = createDataPartition(y = df$att,  # y = our dependent variable.
                                  p = .6,  # Specifies split into 70% & 30%.
                                  list = FALSE,  # Sets results to matrix form. 
                                  times = 1)  # Sets number of partitions to create to 1. 


#Now we can split our data into train and test data using the randomly sampled train_index that we just formed.

train_data = df[train_index,]  # Use train_index of iris data to create train_data.
test_data = df[-train_index,]  # Use whatever that is not in train_index to create test_data.
``` 

```{r,message=FALSE, fig.align = "center", results='asis'}
model = glm(att~.,
            data = train_data,
            family = "binomial", maxit = 100)

res <- predict(model, test_data, type = 'response')

res <- predict(model, train_data, type = 'response')

``` 
The model returns 100% accuracy.
```{r,message=FALSE, fig.align = "center", results='asis'}
confmatrix <- table(Actual_Value = train_data$att, predicted_value = res > 0.5)
confmatrix

(confmatrix[[1,1]] + confmatrix[[2,2]])*100 / sum(confmatrix)
``` 


## Decision tree
```{r,message=FALSE, fig.align = "center", results='asis'}
df <- df %>%
  select(!att)

set.seed(237)

train_index = createDataPartition(y = df$Attrition_Flag,  # y = our dependent variable.
                                  p = .7,  # Specifies split into 70% & 30%.
                                  list = FALSE,  # Sets results to matrix form. 
                                  times = 1)  # Sets number of partitions to create to 1. 


#Now we can split our data into train and test data using the randomly sampled train_index that we just formed.

train_data = df[train_index,]  # Use train_index of iris data to create train_data.
test_data = df[-train_index,]  # Use whatever that is not in train_index to create test_data.
``` 

```{r,message=FALSE, fig.align = "center", results='asis'}
fitControl = trainControl(method = "cv", number = 10, savePredictions = TRUE)

### Create model
#### Check the predicted accuracy of our decision tree model by running it on resamples of our train data. Later we will test the accuracy of the model by running a prediction on our test data.

dt_model = train( `Attrition_Flag`~ ., # Set Y variable followed by '~'. The period indicates to include all variables for prediction. 
                 data = train_data, # Data
                 method = 'rpart', # Specify SVM model
                 trControl = fitControl) # Use cross validation

confusionMatrix(dt_model)
``` 

The model returns 90.5% accuracy. 
We can get a visual of the variable importance.

```{r,message=FALSE, fig.align = "center", results='asis'}
dt_importance <- varImp(dt_model)

ggplot(data = dt_importance, mapping = aes(x = dt_importance[,1])) + # Data & mapping
  geom_boxplot() + # Create box plot
  theme_light() +
  labs(title="Variable importance: Decision tree model",
       fill="",
       x="",
       y="") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
``` 
And a visual of the decision tree.
```{r,message=FALSE, fig.align = "center", results='asis'}
fancyRpartPlot(dt_model$finalModel, sub = '')
``` 

```{r,message=FALSE, fig.align = "center", results='asis'}
prediction_dt = predict(dt_model, test_data)

####Check the proportion of the predictions which were accurate.

t = table(prediction_dt, test_data$Attrition_Flag) %>% # Create prediction table. 
  prop.table() %>% # Convert table values into proportions instead of counts. 
  round(2) # Round numbers to 2 significant values. 
``` 

```{r , echo=FALSE}
kable(t)
```

As we can see, the model returned the right classification for 90% of the observations.

## Random Foorest 
```{r,message=FALSE, fig.align = "center", results='asis'}
##Random Forest
###Create an object for a 10 fold cross validation. We will use this in our train() function to set trControl next.

fitControl = trainControl(method = "cv", number = 10, savePredictions = TRUE)

###Create a training model using train() from the CARET package.

rf_model = train(
  `Attrition_Flag` ~ .,  # Set Y variable followed by "~." to include all variables in formula.
  method = 'rf',  # Set method as random forest.
  trControl = fitControl,  # Set cross validation settings
  data = train_data)  # Set data as train_data. 

###Use the varImp() function to grab the importance of each variable in our random forest model and then plot them.

rf_importance = varImp(rf_model) 
```

```{r,message=FALSE, fig.align = "center", results='asis'}
#### Create box plot of importance of variables
ggplot(data = rf_importance, mapping = aes(x = rf_importance[,1])) + # Data & mapping
  geom_boxplot() + # Create box plot
  labs(title = "Variable importance: Random forest model") + # Title
  theme_light() # Theme
```

```{r,message=FALSE, fig.align = "center", results='asis'}
###Now, lets check the predicted accuracy of the random forest model by running it on resamples of our train data. Later we will test the accuracy of the model by running a prediction on our test data, which is data our model has not seen before.

confusionMatrix(rf_model)

###Prediction: Random forest model - We will now use our created random forest model in order to predict species on our test data (i.e., the data set our ‘machine’ has not seen before).

####Use the created rf_model to run a prediction on the test data.

prediction_rf = predict(rf_model, test_data)
```

```{r,message=FALSE, fig.align = "center", results='asis'}
####Check the accuracy of our random forest model on our test data.

t = table(prediction_rf, test_data$`Attrition_Flag`) %>% # Create prediction table. 
  prop.table() %>% # Convert table values into proportions instead of counts. 
  round(2) # Round numbers to 2 significant values. 

kable(t)
``` 

## Support Vector Machine (SVM)
Lastly the SVM model returns 90% accuracy.
```{r,message=FALSE, fig.align = "center", results='asis'}
##Support Vector Machine (SVM)
###Model the SVM model with a 10 fold cross validation.

fitControl = trainControl(method = "cv", number = 10, savePredictions = TRUE)

###Create a predictor model with the train() function from the CARET package. Specify method = 'svmLinear' to run a SVM model.

svm_model = train(`Attrition_Flag` ~ ., # Set Y variable followed by '~'. The period indicates to include all variables for prediction. 
                  data = train_data, # Data
                  method = 'svmLinear', # Specify SVM model
                  trControl = fitControl) # Use cross validation

###Check the predicted accuracy of our naive Bayes model by running it on resamples of our train data. Later we will test the accuracy of the model by running a prediction on our test data.

confusionMatrix(svm_model)
```


```{r,message=FALSE, fig.align = "center", results='asis'}
###PREDICTION: Support Vector Machine - Use the created svm_model to run a prediction on the test data.

prediction_svm = predict(svm_model, test_data)

####Check the proportion of the predictions which were accurate.

t = table(prediction_svm, test_data$`Attrition_Flag`) %>% # Create prediction table. 
  prop.table() %>% # Convert table values into proportions instead of counts. 
  round(2) # Round numbers to 2 significant values. 

kable(t)
``` 